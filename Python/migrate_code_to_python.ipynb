{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From R to Python\n",
    "\n",
    "\n",
    "```r\n",
    "\n",
    "makeSonnet <- function(verbose=F){\n",
    "  Write = TRUE\n",
    "  State = \"StateFirstProb\"\n",
    "  MarkQuote      <- character()            # Create a vector for storing the new sequence\n",
    "  \n",
    "  ########\n",
    "  # Choose the word for the first position in the sequence:\n",
    "  FirstMarkovWord <- sample(names(ListOfWords[[State]]), 1, rep=TRUE, prob=ListOfWords[[State]])\n",
    "  MarkQuote[1]   <- FirstMarkovWord       # Store the nucleotide for the first position of the sequence\n",
    "  i = 2\n",
    "  # Change to next state\n",
    "  State = \"StateBody\"\n",
    "  if(verbose) {cat(\"\\n\")}\n",
    "  while (Write == TRUE) {\n",
    "    if(verbose) {print (State)}\n",
    "    ### Choose word according to State\n",
    "    PreviousWord <- MarkQuote[i-1]\n",
    "    \n",
    "    # Get the previous nucleotide in the new sequence\n",
    "    # Get the probabilities of the new word, given previous word AND the NEW state\n",
    "    PreviousWord <- gsub(\"*\\\\.[0-9]\", \"\\\\\", PreviousWord)\n",
    "    probabilities  <- TransitionMatrix[PreviousWord,] ## Probabilities of a word given previous word\n",
    "    #\n",
    "    OverlapIndex <- names(ListOfWords[[State]]) %in% names(probabilities)[probabilities != 0] #Posible words given a previous word found in current state\n",
    "    words <- names(ListOfWords[[State]]) [OverlapIndex]\n",
    "    probabilities  <- TransitionMatrix[PreviousWord,words,drop=F]\n",
    "    probabilities\n",
    "    ## Select word and save\n",
    "    if (length(probabilities) != 0) { \n",
    "      NextWords     <- sample(names(probabilities), 1, rep=TRUE, prob=probabilities) #According to transition prob matrix\n",
    "      NextWords <- gsub(\"*\\\\.[0-9]\", \"\\\\\", NextWords)\n",
    "      MarkQuote[i]  <- NextWords          # Store the nucleotide for the current position of the sequence\n",
    "      # If there are no possible words given the current state and previous word, \n",
    "      #select a random from that state without considering previous word\n",
    "    } else { MarkQuote[i]     <- sample(names(ListOfWords[[State]]), 1, rep=TRUE, prob=ListOfWords[[State]])\n",
    "    }     \n",
    "    \n",
    "    # If sentence end, add period. \n",
    "    if (State == \"StateSentenceEnd\") { \n",
    "      MarkQuote[i] <- paste(MarkQuote[i], \". \\n\",sep=\"\", collapse = \"\")}\n",
    "    \n",
    "    ###################################################################################################\n",
    "    \n",
    "    ### Select new state\n",
    "    StateNames <- names(EmissionMatrix[State,])\n",
    "    StateProbs <- EmissionMatrix[State,]\n",
    "    State     <- sample(StateNames, 1, rep=TRUE, prob=StateProbs)\n",
    "    \n",
    "    \n",
    "    ###################################################################################################\n",
    "    ## Check if end sentence. \n",
    "    if (State == \"STOP\") { Write = FALSE}\n",
    "    i=i+1\n",
    "  }\n",
    "  return(MarkQuote)\n",
    "}\n",
    "\n",
    "capitalizeQuote <- function(x) {\n",
    "  substr(x, 1, 1) <- toupper(substr(x, 1, 1))\n",
    "  x\n",
    "}\n",
    "\n",
    "getSonnet <- function(){\n",
    "  tot = 0\n",
    "  count = 0\n",
    "  while (tot < 100 | tot > 110 | count > 100){\n",
    "    outQuote <- makeSonnet()\n",
    "    tot <- sum(nchar(outQuote)) \n",
    "    count = count + 1\n",
    "  }\n",
    "  \n",
    "  outQuote[1] <- capitalizeQuote(outQuote[1])\n",
    "  MarkQuote <- paste(outQuote,collapse = \" \")\n",
    "  return (MarkQuote)\n",
    "}\n",
    "\n",
    "verse <- getSonnet()\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/jrm/Desktop/portfolio/sonnetGenText/Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Read TSV files normally.\n",
    "EmissionMatrix = pd.read_csv(\"/Users/jrm/Desktop/portfolio/sonnetGenText/Python/EmissionMatrix.tsv\", sep=\"\\t\")\n",
    "SingleWordProbs = pd.read_csv(\"/Users/jrm/Desktop/portfolio/sonnetGenText/Python/SingleWordProbs.tsv\", sep=\"\\t\")\n",
    "TransitionMatrix = pd.read_csv(\"/Users/jrm/Desktop/portfolio/sonnetGenText/Python/TransitionMatrix.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "with open('/Users/jrm/Desktop/portfolio/sonnetGenText/Python/ListOfWords.json') as f:\n",
    "    ListOfWords = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thy grace is. \n",
      " ay fill it. \n",
      " great receipt with white. \n",
      " though mounted on better. \n",
      " lifts up the past. \n",
      " bear his lie.\n"
     ]
    }
   ],
   "source": [
    "def clean_list_of_words(list_of_words):\n",
    "    \"\"\"\n",
    "    Remove trailing .<number> from each word key and aggregate probabilities.\n",
    "    Then normalize the probabilities for each state.\n",
    "    \"\"\"\n",
    "    cleaned = {}\n",
    "    for state, words_dict in list_of_words.items():\n",
    "        new_words = {}\n",
    "        for word, prob in words_dict.items():\n",
    "            # Remove only at the end\n",
    "            base_word = re.sub(r'\\.\\d+$', '', word)\n",
    "            new_words[base_word] = new_words.get(base_word, 0) + prob\n",
    "        # Normalize probabilities for this state.\n",
    "        total = sum(new_words.values())\n",
    "        for word in new_words:\n",
    "            new_words[word] /= total\n",
    "        cleaned[state] = new_words\n",
    "    return cleaned\n",
    "\n",
    "# Clean the ListOfWords dictionary.\n",
    "ListOfWords = clean_list_of_words(raw_ListOfWords)\n",
    "\n",
    "def make_sonnet(debugging=False):\n",
    "    write = True\n",
    "    state = \"StateFirstProb\"\n",
    "    mark_quote = []\n",
    "    \n",
    "    if debugging:\n",
    "        print(f\"Initial state: {state}\")\n",
    "        print(\"ListOfWords for initial state:\", ListOfWords[state])\n",
    "    \n",
    "    # Sample the first word using probabilities from ListOfWords[state].\n",
    "    words = list(ListOfWords[state].keys())\n",
    "    probs = np.array(list(ListOfWords[state].values()), dtype=float)\n",
    "    probs /= probs.sum()\n",
    "    first_word = np.random.choice(words, p=probs)\n",
    "    if debugging:\n",
    "        print(f\"First word (raw): {first_word}\")\n",
    "    mark_quote.append(first_word)\n",
    "    \n",
    "    # Set the state for subsequent words.\n",
    "    state = \"StateBody\"\n",
    "    if debugging:\n",
    "        print(f\"State changed to: {state}\")\n",
    "    \n",
    "    while write:\n",
    "        if debugging:\n",
    "            print(\"\\nCurrent state:\", state)\n",
    "            print(\"Current mark_quote:\", mark_quote)\n",
    "        \n",
    "        # Get the previous word and clean it.\n",
    "        previous_word = mark_quote[-1]\n",
    "        cleaned_prev = re.sub(r\"\\.\\d+\", \"\", previous_word)\n",
    "        if debugging and previous_word != cleaned_prev:\n",
    "            print(f\"Cleaned previous word: '{previous_word}' -> '{cleaned_prev}'\")\n",
    "        previous_word = cleaned_prev\n",
    "        \n",
    "        # Get transition probabilities for the previous word.\n",
    "        if previous_word in TransitionMatrix.index:\n",
    "            probabilities_series = TransitionMatrix.loc[previous_word]\n",
    "            if debugging:\n",
    "                print(f\"Transition probabilities for '{previous_word}':\")\n",
    "                print(probabilities_series[probabilities_series != 0])\n",
    "        else:\n",
    "            probabilities_series = pd.Series(np.ones(len(TransitionMatrix.columns)), index=TransitionMatrix.columns)\n",
    "            if debugging:\n",
    "                print(f\"'{previous_word}' not found in TransitionMatrix. Using uniform probabilities.\")\n",
    "        \n",
    "        # Determine valid words based on the current state's list and nonzero transition probabilities.\n",
    "        current_state_words = list(ListOfWords[state].keys())\n",
    "        valid_words = probabilities_series[probabilities_series != 0].index.tolist()\n",
    "        words_overlap = [w for w in current_state_words if w in valid_words]\n",
    "        if debugging:\n",
    "            print(\"Valid words from TransitionMatrix:\", valid_words)\n",
    "            print(\"Words in current state:\", current_state_words)\n",
    "            print(\"Overlap words:\", words_overlap)\n",
    "        \n",
    "        if words_overlap:\n",
    "            probs = probabilities_series[words_overlap].values.astype(float)\n",
    "            if probs.sum() > 0:\n",
    "                probs /= probs.sum()\n",
    "            else:\n",
    "                probs = np.ones(len(words_overlap)) / len(words_overlap)\n",
    "            next_word = np.random.choice(words_overlap, p=probs)\n",
    "            cleaned_next = re.sub(r\"\\.\\d+\", \"\", next_word)\n",
    "            if debugging and next_word != cleaned_next:\n",
    "                print(f\"Cleaned next word: '{next_word}' -> '{cleaned_next}'\")\n",
    "            next_word = cleaned_next\n",
    "            mark_quote.append(next_word)\n",
    "        else:\n",
    "            # Fallback: sample ignoring transition probabilities.\n",
    "            all_words = list(ListOfWords[state].keys())\n",
    "            probs_all = np.array(list(ListOfWords[state].values()), dtype=float)\n",
    "            probs_all /= probs_all.sum()\n",
    "            next_word = np.random.choice(all_words, p=probs_all)\n",
    "            if debugging:\n",
    "                print(\"Fallback next word (no overlap):\", next_word)\n",
    "            mark_quote.append(next_word)\n",
    "        \n",
    "        # Append punctuation if current state indicates sentence end.\n",
    "        if state == \"StateSentenceEnd\":\n",
    "            mark_quote[-1] = mark_quote[-1] + \". \\n\"\n",
    "            if debugging:\n",
    "                print(\"Appended sentence-ending punctuation.\")\n",
    "        \n",
    "        # Select new state based on the EmissionMatrix.\n",
    "        state_names = list(EmissionMatrix.columns)\n",
    "        state_probs = EmissionMatrix.loc[state].values.astype(float)\n",
    "        if state_probs.sum() > 0:\n",
    "            state_probs /= state_probs.sum()\n",
    "        else:\n",
    "            state_probs = np.ones(len(state_names)) / len(state_names)\n",
    "        new_state = np.random.choice(state_names, p=state_probs)\n",
    "        if debugging:\n",
    "            print(f\"State transition: {state} -> {new_state}\")\n",
    "        state = new_state\n",
    "        \n",
    "        # Stop if new state is \"STOP\".\n",
    "        if state == \"STOP\":\n",
    "            if debugging:\n",
    "                print(\"State is STOP. Ending sonnet generation.\")\n",
    "            write = False\n",
    "            \n",
    "    return mark_quote\n",
    "\n",
    "def capitalize_quote(text):\n",
    "    if not text:\n",
    "        return text\n",
    "    return text[0].upper() + text[1:]\n",
    "\n",
    "def get_sonnet(debugging=False):\n",
    "    tot = 0\n",
    "    count = 0\n",
    "    out_quote = []\n",
    "    # Generate until total character length is between 100 and 110 or max 100 attempts.\n",
    "    while (tot < 100 or tot > 110) and count < 100:\n",
    "        if debugging:\n",
    "            print(f\"\\nAttempt {count+1}:\")\n",
    "        out_quote = make_sonnet(debugging)\n",
    "        tot = sum(len(word) for word in out_quote)\n",
    "        if debugging:\n",
    "            print(f\"Total characters in sonnet: {tot}\")\n",
    "        count += 1\n",
    "    if out_quote:\n",
    "        out_quote[0] = capitalize_quote(out_quote[0])\n",
    "    mark_quote = \" \".join(out_quote)\n",
    "    return mark_quote\n",
    "\n",
    "# Toggle debugging here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weary travels i. \n",
      " tell oer incertainty. \n",
      " harsh featureless and by. \n",
      " beautys waste defeated. \n",
      " doubting the pain.\n",
      "\n",
      "\n",
      "Music playst hand. \n",
      " through windows alchemy. \n",
      " return forgetful muse. \n",
      " tempteth my better is. \n",
      " making worse age.\n",
      "\n",
      "\n",
      "O! abundance lies. \n",
      " though less truth. \n",
      " still losing her. \n",
      " be near sin you i. \n",
      " harsh featureless will. \n",
      " look what you.\n",
      "\n",
      "\n",
      "Was summers flower is. \n",
      " whereon the breath. \n",
      " take all men make. \n",
      " beated and therefore i. \n",
      " slandring creation die.\n",
      "\n",
      "\n",
      "Shall outlive long since mind. \n",
      " others thou art. \n",
      " loving breast so. \n",
      " oerchargd with me thus. \n",
      " whereon my old dote.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(get_sonnet(debugging=False))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
